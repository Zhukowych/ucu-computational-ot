{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical fundamentals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let consider the modification to original Kantorovich problem:\n",
    "\n",
    "$$L_C^\\epsilon(a, b) = \\min_{\\mathbf{P}\\in \\mathbf{U(a, b)}} \\langle \\mathbf{P}, \\mathbf{C} \\rangle - \\epsilon\\mathbf{H(P)}$$\n",
    "\n",
    "Here we subtracted entropy of a coupling matrix:\n",
    "\n",
    "$$\\mathbf{H(P)} = -\\sum P_{ij}(logP_{ij} - 1)$$ \n",
    "\n",
    "Which is strongly concave (**TODO**: find proof), thus as we deduct it from $\\langle \\mathbf{P}, \\mathbf{C} \\rangle$ then optimization problem becomes a convex optimization problem.\n",
    "\n",
    "**Why?**: I belive that $\\langle \\mathbf{P}, \\mathbf{C} \\rangle$ is not strictly convex as it a linear function thus spans a hyperplane, and adding a 1-strongly convex entropy necessarily results in strictly convex one.  \n",
    "\n",
    "As the resulting function is strictly convex it's guarantees existence of one optimal solution, that can be found in the following way using Lagrange multiplier method.\n",
    "\n",
    "$$\\mathcal{L(\\mathbf{P}, \\mathbf{\\lambda}, \\mathbf{\\gamma})} = \\langle \\mathbf{P}, \\mathbf{C} \\rangle - \\langle \\mathbf{P}\\mathbb{1}_m - a, \\mathbb{\\lambda} \\rangle - \\langle \\mathbf{P}^\\top\\mathbb{1}_n - b, \\mathbb{\\gamma} \\rangle $$\n",
    "\n",
    "Searching for stationary points yield the solution if following form:\n",
    "\n",
    "$$P_{ij}=\\exp(\\mathbf{\\lambda}_i/\\epsilon)\\exp(- C_{ij}/\\epsilon)\\exp(\\mathbf{\\gamma}_j/ \\epsilon)$$\n",
    "\n",
    "If we take all values of first exponent to vector $\\mathbf{u}$, last to $\\mathbf{v}$, and middle to matrix $\\mathbf{K}$, then\n",
    "\n",
    "$$\\mathbf{P}^{*} = diag\\{\\mathbf{u}\\}\\mathbf{K}diag\\{\\mathbf{v}\\}$$\n",
    "\n",
    "Note that this solution must satisfy $P^*\\mathbb{1}_m=\\mathbf{a}$ and $(\\mathbf{P}^*)^\\top 1_n=\\mathbf{b}$. Those constraints can be rewritten as $\\mathbf{u}\\odot (\\mathbf{Kv}) = \\mathbf{a}$ and $\\mathbf{v}\\odot (\\mathbf{K^\\top u}) = \\mathbf{a}$ (as matrix-vector multiplication is linear combination of matrix column and then the sum is multiplied by $\\mathbf{u}_j$ to get the required constraint). Thus, iterative algorithm can be applied. Take $\\mathbf{v}^{(0)} = \\mathbf{1}$ and update rules\n",
    "\n",
    "$$\\mathbf{u}^{(l+1)} = \\frac{\\mathbf{a}}{\\mathbf{Kv}^{(l)}}$$\n",
    "\n",
    "$$\\mathbf{v}^{(l+1)} = \\frac{\\mathbf{b}}{\\mathbf{K^\\top v}^{(l+1)}}$$\n",
    "\n",
    "It is shown (**TODO:** add proof) that using these iteratioins solution converges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
